{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2286172,
          "sourceType": "datasetVersion",
          "datasetId": 1377494
        }
      ],
      "dockerImageVersionId": 30066,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeoZ666/classroom_DL_EXP/blob/main/FashionMNIST_Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Autoencoders"
      ],
      "metadata": {
        "id": "6Pu36yJJwBCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"left\">\n",
        "<img src=\"https://miro.medium.com/max/3110/0*uq2_ZipB9TqI9G_k\"/>\n",
        "</p>"
      ],
      "metadata": {
        "id": "spjr-Zlf6In_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>This notebook is aimed at Machine Learning and Deep Learning beginners who are interested in getting a brief understanding of the underlying concepts behind <strong>autoencoders</strong><p>"
      ],
      "metadata": {
        "id": "YryyOQl54Bxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objectives\n",
        "\n",
        "<ol>\n",
        "<li>To demonstrate how we can train an AUTOENCODER over <b>Fashion MNIST Dataset</b></li>\n",
        "<li>To demostrate how we can use an AUTOENCODER for <strong>Face reconstruction</strong></li>\n",
        "<li>To demonstrate how we can perform <b>Image Denoising</b> via an AUTOENCODER</li>\n",
        "<li>To demonstrate how we can build a <b>Face Recognition</b> using an AUTOENCODER</li>\n",
        "</ol>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "38y-6R1g4vhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is an **AUTOENCODER** ?"
      ],
      "metadata": {
        "id": "vpjnvgJe4ddq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<ul>\n",
        "<li><b><i>Autoencoders</i></b> are a type of neural network that attempts to mimic its input as closely as possible to its output.</li>\n",
        "<li>It has aims to take an input, transform it into a reduced representation called <b>Embedding or Latent Space representation</b>. Then, this embedding is transformed back into the original input.</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "pPBovx7K7qBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><b>Architecture of Autoencoders</b><h3>\n",
        "<p>An Autoencoder consists of three main components : </p>\n",
        "\n",
        "* Encoder\n",
        "* Embedding\n",
        "* Decoder\n",
        "\n",
        "<b><em>NOTE: The decoder architecture is the mirror image of an encoder</em></b>"
      ],
      "metadata": {
        "id": "e2m4iiCE-RWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://miro.medium.com/max/1784/1*CRP98rEvxpcdo6gJI3tXWA.png\"/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "7jTbN9qoDDM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><b>Types of Autoencoders : </b></h3>\n",
        "<p>\n",
        "<ol>\n",
        "<li>Vanilla Autoencoder</li>\n",
        "<li>Sparse Autoencoder</li>\n",
        "<li>Convolutional Autoencoder</li>\n",
        "<li>Denoising Autoencoder</li>\n",
        "<li>Variational Autoencoder</li>\n",
        "</ol>\n",
        "etc...\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "6L-xle7ODgdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://static.packt-cdn.com/products/9781789612011/graphics/06965e3d-46b3-418b-a4c6-a39df696159c.png\"/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "u7yIOOqxDSAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Required Modules"
      ],
      "metadata": {
        "id": "K1A94aRKG7XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "print(tf.__version__)\n",
        "print(\"ALL MODULES IMPORTED SUCCESSFULLY\")"
      ],
      "metadata": {
        "id": "JvLYFfEfG-1L",
        "outputId": "cd527d27-df02-4d01-ddbc-3ab7d2e1e7f6",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:06:42.972169Z",
          "iopub.execute_input": "2021-05-30T14:06:42.972525Z",
          "iopub.status.idle": "2021-05-30T14:06:48.990843Z",
          "shell.execute_reply.started": "2021-05-30T14:06:42.972447Z",
          "shell.execute_reply": "2021-05-30T14:06:48.989944Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n",
            "ALL MODULES IMPORTED SUCCESSFULLY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Objective#1 : Training an AUTOENCODER over Fashion MNIST Dataset**"
      ],
      "metadata": {
        "id": "83hp4PMAGhfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Loading Dataset**\n",
        "<ul>\n",
        "<li><p><strong>DESC: </strong>Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.</p></li>\n",
        "\n",
        "<li><p><strong>Why we are dividing the arrays by 255 ??</strong>\n",
        "<ol>\n",
        "<li>To prevent overshooting of activation values.</li>\n",
        "<li>To have a homogenous distribution of weights and biases.</li>\n",
        "</ol></p></li>\n",
        "<ul>"
      ],
      "metadata": {
        "id": "uQRMVVeGZwK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "X_train = X_train.astype('float32')/255.\n",
        "X_test = X_test.astype('float32') /255.\n",
        "\n",
        "print()\n",
        "print(f\"Shape of Train Data: {X_train.shape}\")\n",
        "print(f\"Shape of Test Data: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "463TEwlt6IFj",
        "outputId": "3afcae38-1f88-461c-9700-de6e1a8218fc",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:06:48.993018Z",
          "iopub.execute_input": "2021-05-30T14:06:48.993372Z",
          "iopub.status.idle": "2021-05-30T14:06:50.415327Z",
          "shell.execute_reply.started": "2021-05-30T14:06:48.993337Z",
          "shell.execute_reply": "2021-05-30T14:06:50.414362Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "Shape of Train Data: (60000, 28, 28)\n",
            "Shape of Test Data: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Sample Images**"
      ],
      "metadata": {
        "id": "nWfrgN66hqb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashionMNIST_classes = {0:\"T-shirt/top\", 1:\"Trouser\",\n",
        "                        2:\"Pullover\", 3:\"Dress\",\n",
        "                        4:\"Coat\", 5:\"Sandal\",\n",
        "                        6:\"Shirt\", 7:\"Sneaker\",\n",
        "                        8:\"Bag\", 9:\"Ankle boot\"}"
      ],
      "metadata": {
        "id": "m4y_fT__jK60",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:06:50.416592Z",
          "iopub.execute_input": "2021-05-30T14:06:50.41694Z",
          "iopub.status.idle": "2021-05-30T14:06:50.422547Z",
          "shell.execute_reply.started": "2021-05-30T14:06:50.41691Z",
          "shell.execute_reply": "2021-05-30T14:06:50.421709Z"
        },
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize = (20, 4))\n",
        "for i in range(n):\n",
        "    plt.subplot(1, n, i+1)\n",
        "    idx = np.random.randint(i, len(X_train))\n",
        "    plt.imshow(X_train[idx])\n",
        "    plt.title(fashionMNIST_classes[y_train[idx]])\n",
        "    plt.gray()\n",
        "    plt.xticks([]); plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pWHf7CA2e260",
        "outputId": "a5368dce-d1c3-49b3-81b5-773148468916",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:06:50.42414Z",
          "iopub.execute_input": "2021-05-30T14:06:50.424759Z",
          "iopub.status.idle": "2021-05-30T14:06:50.788817Z",
          "shell.execute_reply.started": "2021-05-30T14:06:50.424723Z",
          "shell.execute_reply": "2021-05-30T14:06:50.787964Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Building our Autoencoder**"
      ],
      "metadata": {
        "id": "VX4gVjVKj_sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 64\n",
        "\n",
        "class MNIST_AutoEncoder(Model):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(MNIST_AutoEncoder, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # Building our Encoder\n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Input(shape=(28, 28)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(self.embedding_dim, activation = \"relu\"),\n",
        "        ])\n",
        "\n",
        "        # Building our Decoder\n",
        "        self.decoder = tf.keras.Sequential([\n",
        "            layers.Input(shape=(self.embedding_dim)),\n",
        "            layers.Dense(784, activation=\"sigmoid\"),\n",
        "            layers.Reshape((28, 28))\n",
        "        ])\n",
        "\n",
        "    def call(self, X):\n",
        "        encoded = self.encoder(X)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded"
      ],
      "metadata": {
        "id": "xVtQTx8JiwZ6",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:06:50.79138Z",
          "iopub.execute_input": "2021-05-30T14:06:50.791729Z",
          "iopub.status.idle": "2021-05-30T14:06:50.798848Z",
          "shell.execute_reply.started": "2021-05-30T14:06:50.791695Z",
          "shell.execute_reply": "2021-05-30T14:06:50.797884Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vanillaAutoencoder = MNIST_AutoEncoder(embedding_dim)\n",
        "vanillaAutoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
      ],
      "metadata": {
        "id": "AxfS_GuzpNaF",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:06:50.800768Z",
          "iopub.execute_input": "2021-05-30T14:06:50.801149Z",
          "iopub.status.idle": "2021-05-30T14:06:53.333541Z",
          "shell.execute_reply.started": "2021-05-30T14:06:50.801102Z",
          "shell.execute_reply": "2021-05-30T14:06:53.332652Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "c0dc7cf1-badb-48c8-bf12-da336d47bb24"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'embedding_dim' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f46644c8954d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvanillaAutoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST_AutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvanillaAutoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embedding_dim' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vanillaAutoencoder.encoder.summary()"
      ],
      "metadata": {
        "id": "Qso2VHfapz_K",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:06:53.33487Z",
          "iopub.execute_input": "2021-05-30T14:06:53.33528Z",
          "iopub.status.idle": "2021-05-30T14:06:53.343751Z",
          "shell.execute_reply.started": "2021-05-30T14:06:53.335244Z",
          "shell.execute_reply": "2021-05-30T14:06:53.342752Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vanillaAutoencoder.decoder.summary()"
      ],
      "metadata": {
        "id": "pBVbzN0WqDTi",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:06:53.345313Z",
          "iopub.execute_input": "2021-05-30T14:06:53.345871Z",
          "iopub.status.idle": "2021-05-30T14:06:53.35455Z",
          "shell.execute_reply.started": "2021-05-30T14:06:53.345836Z",
          "shell.execute_reply": "2021-05-30T14:06:53.353702Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_training_history = vanillaAutoencoder.fit(x = X_train, y = X_train,\n",
        "                                       epochs = 10,\n",
        "                                       batch_size = 16,\n",
        "                                       shuffle = True,\n",
        "                                       validation_data = (X_test, X_test))"
      ],
      "metadata": {
        "id": "i4gwTi0vrqOU",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:06:53.356212Z",
          "iopub.execute_input": "2021-05-30T14:06:53.356721Z",
          "iopub.status.idle": "2021-05-30T14:07:49.013213Z",
          "shell.execute_reply.started": "2021-05-30T14:06:53.356685Z",
          "shell.execute_reply": "2021-05-30T14:07:49.012488Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Results**"
      ],
      "metadata": {
        "id": "JQc_lXPJwhXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing our training and validation losses\n",
        "train_loss = mnist_training_history.history[\"loss\"]\n",
        "val_loss = mnist_training_history.history[\"val_loss\"]\n",
        "epochs = [d for d in range(1,11)]\n",
        "\n",
        "# Code for plotting train and val loss\n",
        "plt.figure(figsize=(18, 10))\n",
        "plt.plot(epochs, train_loss, '-r', label=\"Training\")\n",
        "plt.plot(epochs, val_loss, '--b', label=\"Validation\")\n",
        "plt.title(\"LOSS Curve for Fashion MNIST\")\n",
        "plt.grid(True)\n",
        "plt.xlabel('Epochs'); plt.ylabel(\"LOSS\")\n",
        "plt.legend()\n",
        "plt.xticks([d for d in range(1, 11)])\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "6nPxWWjAtYQU",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:07:49.016778Z",
          "iopub.execute_input": "2021-05-30T14:07:49.017032Z",
          "iopub.status.idle": "2021-05-30T14:07:49.223247Z",
          "shell.execute_reply.started": "2021-05-30T14:07:49.017007Z",
          "shell.execute_reply": "2021-05-30T14:07:49.222588Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# collecting the encoded and decoded versions of our test data\n",
        "encoded_imgs = vanillaAutoencoder.encoder(X_test).numpy()\n",
        "decoded_imgs = vanillaAutoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "# Plotting our original and reconstructed images\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "  # To display the original images\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  idx = np.random.randint(i, len(X_test))\n",
        "  plt.imshow(X_test[idx])\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # To display reconstructed images\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(decoded_imgs[idx])\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ddPsIsPkup-N",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:07:49.225598Z",
          "iopub.execute_input": "2021-05-30T14:07:49.225969Z",
          "iopub.status.idle": "2021-05-30T14:07:50.111263Z",
          "shell.execute_reply.started": "2021-05-30T14:07:49.225933Z",
          "shell.execute_reply": "2021-05-30T14:07:50.110369Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Objective#2 : Face reconstruction via autoencoder**"
      ],
      "metadata": {
        "id": "GMFLmmqy1_aD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Loading Data**\n",
        "<ul>\n",
        "<p><strong>DESC: </strong></p>\n",
        "<li>Self-made dataset by ML4e members.</li>\n",
        "<li>It has ~2k images for training and ~1k for validation.</li>\n",
        "<li>Images are of RGB format</li>\n",
        "<li># of classes : 6</li>\n",
        "<li>Images has variations like\n",
        "<ol>\n",
        "<li>Different facial experssions</li>\n",
        "<li>Lighting conditions</li>\n",
        "<li>Face alignments</li>\n",
        "</ol>\n",
        "\n",
        "</li>\n",
        "\n",
        "<ul>"
      ],
      "metadata": {
        "id": "yBTPYItWMpfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_LOC = \"../input/only-faces/Only_faces/Validation\"\n",
        "TRAIN_LOC = \"../input/only-faces/Only_faces/Training\""
      ],
      "metadata": {
        "id": "KFtiqJDzPhiR",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:15:08.671834Z",
          "iopub.execute_input": "2021-05-30T14:15:08.672175Z",
          "iopub.status.idle": "2021-05-30T14:15:08.675471Z",
          "shell.execute_reply.started": "2021-05-30T14:15:08.672144Z",
          "shell.execute_reply": "2021-05-30T14:15:08.67468Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><b>Function for loading train and validation data</b></p>"
      ],
      "metadata": {
        "id": "My7KRm_GF27i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_data(img_folder_path, normalize = True):\n",
        "    labels = []\n",
        "    images = []\n",
        "    for class_ in os.listdir(img_folder_path):\n",
        "        img_paths = f\"{img_folder_path}/{class_}\"\n",
        "        for img in os.listdir(img_paths):\n",
        "            image = cv2.imread(os.path.join(img_paths, img))\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image = image.astype('float32')\n",
        "            if normalize:\n",
        "                image = image/255.\n",
        "            image = cv2.resize(image, (128, 128))\n",
        "\n",
        "            images.append(image)\n",
        "            labels.append(class_)\n",
        "    images = np.array(images)\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "4BJ0w7koQe17",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:15:10.371586Z",
          "iopub.execute_input": "2021-05-30T14:15:10.371946Z",
          "iopub.status.idle": "2021-05-30T14:15:10.378086Z",
          "shell.execute_reply.started": "2021-05-30T14:15:10.371909Z",
          "shell.execute_reply": "2021-05-30T14:15:10.37714Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs, train_labels = build_data(TRAIN_LOC)\n",
        "val_imgs, val_labels = build_data(VAL_LOC)"
      ],
      "metadata": {
        "id": "ihHg0Ojp5NtI",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:15:11.391717Z",
          "iopub.execute_input": "2021-05-30T14:15:11.392042Z",
          "iopub.status.idle": "2021-05-30T14:15:23.858176Z",
          "shell.execute_reply.started": "2021-05-30T14:15:11.392014Z",
          "shell.execute_reply": "2021-05-30T14:15:23.857377Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of TRAIN DATA : {train_imgs.shape}\")\n",
        "print(f\"Shape of VAL DATA : {val_imgs.shape}\")"
      ],
      "metadata": {
        "id": "KlBn9Ki25sec",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:15:23.859941Z",
          "iopub.execute_input": "2021-05-30T14:15:23.860262Z",
          "iopub.status.idle": "2021-05-30T14:15:23.865715Z",
          "shell.execute_reply.started": "2021-05-30T14:15:23.860229Z",
          "shell.execute_reply": "2021-05-30T14:15:23.864838Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Sample Images**"
      ],
      "metadata": {
        "id": "xV6_p3UXH60g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5\n",
        "plt.figure(figsize = (20, 17))\n",
        "for i in range(n):\n",
        "    plt.subplot(1, n, i+1)\n",
        "    idx = np.random.randint(i, len(train_imgs))\n",
        "    plt.imshow(train_imgs[idx])\n",
        "    plt.title(train_labels[idx])\n",
        "    plt.gray()\n",
        "    plt.xticks([]); plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sfel4uOB6OJg",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:15:23.867046Z",
          "iopub.execute_input": "2021-05-30T14:15:23.867658Z",
          "iopub.status.idle": "2021-05-30T14:15:24.204079Z",
          "shell.execute_reply.started": "2021-05-30T14:15:23.867605Z",
          "shell.execute_reply": "2021-05-30T14:15:24.201018Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Building our Autoencoder**"
      ],
      "metadata": {
        "id": "DKvs_v11NLVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Face_Autoencoder:\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 encoder_conv_filters,\n",
        "                 encoder_conv_kernel_size,\n",
        "                 encoder_conv_strides,\n",
        "                 decoder_conv_t_filters,\n",
        "                 decoder_conv_t_kernel_size,\n",
        "                 decoder_conv_t_strides,\n",
        "                 z_dim,\n",
        "                 use_batch_norm = False,\n",
        "                 use_dropout= False\n",
        "                ):\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.encoder_conv_filters = encoder_conv_filters\n",
        "        self.encoder_conv_kernel_size = encoder_conv_kernel_size\n",
        "        self.encoder_conv_strides = encoder_conv_strides\n",
        "\n",
        "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
        "        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\n",
        "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.use_batch_norm = use_batch_norm\n",
        "        self.use_dropout = use_dropout\n",
        "\n",
        "        self.n_layers_encoder = len(encoder_conv_filters)\n",
        "        self.n_layers_decoder = len(decoder_conv_t_filters)\n",
        "\n",
        "    def build(self):\n",
        "        # Encoder\n",
        "        encoder_input = layers.Input(shape=self.input_dim, name='encoder_input')\n",
        "\n",
        "        x = encoder_input\n",
        "\n",
        "        for i in range(self.n_layers_encoder):\n",
        "\n",
        "            conv_layer = layers.Conv2D(\n",
        "                filters = self.encoder_conv_filters[i],\n",
        "                kernel_size = self.encoder_conv_kernel_size[i],\n",
        "                strides = self.encoder_conv_strides[i],\n",
        "                padding = 'same',\n",
        "                name = 'encoder_conv_' + str(i)\n",
        "                )\n",
        "\n",
        "            x = conv_layer(x)\n",
        "\n",
        "            if self.use_batch_norm:\n",
        "                x = layers.BatchNormalization()(x)\n",
        "\n",
        "            x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "            if self.use_dropout:\n",
        "                x = layers.Dropout(rate = 0.25)(x)\n",
        "\n",
        "\n",
        "        shape_before_flattening = K.int_shape(x)[1:]\n",
        "\n",
        "        x = layers.Flatten()(x)\n",
        "        embedding = layers.Dense(128, name=\"Embedding\")(x)\n",
        "\n",
        "        # DECODER\n",
        "        x = layers.Dense(np.prod(shape_before_flattening))(embedding)\n",
        "        x = layers.Reshape(shape_before_flattening)(x)\n",
        "\n",
        "        for i in range(self.n_layers_decoder):\n",
        "            conv_t_layer = layers.Conv2DTranspose(\n",
        "                filters = self.decoder_conv_t_filters[i],\n",
        "                kernel_size = self.decoder_conv_t_kernel_size[i],\n",
        "                strides = self.decoder_conv_t_strides[i],\n",
        "                padding = 'same',\n",
        "                name = 'decoder_conv_t_' + str(i)\n",
        "                )\n",
        "\n",
        "            x = conv_t_layer(x)\n",
        "\n",
        "            if i < self.n_layers_decoder - 1:\n",
        "                if self.use_batch_norm:\n",
        "                    x = layers.BatchNormalization()(x)\n",
        "                x = layers.Activation('relu')(x)\n",
        "                if self.use_dropout:\n",
        "                    x = layers.Dropout(rate = 0.25)(x)\n",
        "            else:\n",
        "              x = layers.Activation('sigmoid')(x)\n",
        "\n",
        "\n",
        "        decoder_output = x\n",
        "\n",
        "        ae = Model(inputs=encoder_input, outputs=decoder_output, name=\"Face_Autoencoder\")\n",
        "        print(ae.summary())\n",
        "        return ae\n",
        "\n",
        "\n",
        "    def __str__():\n",
        "        return \"FACE AUTOENCODER\""
      ],
      "metadata": {
        "id": "VQB8yIyCHL0F",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:15:24.205217Z",
          "iopub.execute_input": "2021-05-30T14:15:24.205529Z",
          "iopub.status.idle": "2021-05-30T14:15:24.220096Z",
          "shell.execute_reply.started": "2021-05-30T14:15:24.205498Z",
          "shell.execute_reply": "2021-05-30T14:15:24.219268Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (128, 128, 3)\n",
        "fae = Face_Autoencoder(input_dim = IMG_SHAPE,\n",
        "                    encoder_conv_filters=[32,64,64,64],\n",
        "                    encoder_conv_kernel_size=[3,3,3,3],\n",
        "                    encoder_conv_strides=[2,2,2,2],\n",
        "                    decoder_conv_t_filters=[64,64,32,3],\n",
        "                    decoder_conv_t_kernel_size=[3,3,3,3],\n",
        "                    decoder_conv_t_strides=[2,2,2,2],\n",
        "                    z_dim=128,\n",
        "                    use_batch_norm = False,\n",
        "                    use_dropout = False)"
      ],
      "metadata": {
        "id": "E-tM3go3SWDa",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:15:24.222106Z",
          "iopub.execute_input": "2021-05-30T14:15:24.222616Z",
          "iopub.status.idle": "2021-05-30T14:15:24.234997Z",
          "shell.execute_reply.started": "2021-05-30T14:15:24.222578Z",
          "shell.execute_reply": "2021-05-30T14:15:24.234303Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_ae = fae.build()"
      ],
      "metadata": {
        "id": "Lqt7VYHWScyG",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:15:24.236579Z",
          "iopub.execute_input": "2021-05-30T14:15:24.237049Z",
          "iopub.status.idle": "2021-05-30T14:15:24.357507Z",
          "shell.execute_reply.started": "2021-05-30T14:15:24.237013Z",
          "shell.execute_reply": "2021-05-30T14:15:24.356641Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(face_ae, show_shapes = True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "Pj4B7_HOaEK6",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:15:24.358814Z",
          "iopub.execute_input": "2021-05-30T14:15:24.359145Z",
          "iopub.status.idle": "2021-05-30T14:15:25.027492Z",
          "shell.execute_reply.started": "2021-05-30T14:15:24.35911Z",
          "shell.execute_reply": "2021-05-30T14:15:25.026564Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Training our Autoencoder**"
      ],
      "metadata": {
        "id": "2XLO_IRidVOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4><b>Callbacks : </b> A callback is a powerful tool to customize the behavior of your model during training, evaluation, or inference.</h4>\n",
        "<h4>Tensorflow has some built-in callbacks which we can access from tf.keras.callback module</h4>\n",
        "<h4>Examples ...</h4>\n",
        "<ul>\n",
        "<li>Wants to visualize your training process : <strong>Tensorboard</strong></li>\n",
        "<li>Wants to schedule your LR while training: <strong>LearningRateSchedular</strong></li>\n",
        "<li>Wants to save best weights in the training process : <strong>ModelCheckpoint</strong></li>\n",
        "<li>Wants if stop the training before the completion of all epochs : <strong>EarlyStopping</strong></li>\n",
        "</ul>\n",
        "<p>Tensorflow also has provided a Class <b>Callback</b> which helps us to create some custom callbacks</p>"
      ],
      "metadata": {
        "id": "0ulGjPUnICDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Hyperparamters\n",
        "LR = 1e-3\n",
        "BS = 16\n",
        "EPOCHS = 20\n",
        "\n",
        "# Defining Callbacks\n",
        "class ShowLearning(Callback):\n",
        "    def on_epoch_end(self, epoch, logs = {}):\n",
        "\n",
        "        original_imgs = [\n",
        "                val_imgs[val_labels.index('Subject1') + 17],\n",
        "                val_imgs[val_labels.index('Subject2')],\n",
        "                val_imgs[val_labels.index('Subject3')],\n",
        "                val_imgs[val_labels.index('Subject4') + 2],\n",
        "                train_imgs[train_labels.index('Subject5') + 7],\n",
        "                val_imgs[val_labels.index('Subject6') + 4]\n",
        "                ]\n",
        "        decoded_imgs = []\n",
        "\n",
        "        for img in original_imgs:\n",
        "            decoded_imgs.append(face_ae.predict(np.array([img]))[0])\n",
        "\n",
        "        n = len(original_imgs)\n",
        "        plt.figure(figsize=(20, 7))\n",
        "        for i in range(1, n + 1):\n",
        "            # Display original\n",
        "            ax = plt.subplot(2, n, i)\n",
        "            plt.imshow(original_imgs[i-1]);\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "            plt.title(\"Original\")\n",
        "\n",
        "            # Display reconstruction\n",
        "            ax = plt.subplot(2, n, i + n)\n",
        "            plt.imshow(decoded_imgs[i-1]);\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "            plt.title(\"Reconstructed\")\n",
        "\n",
        "        plt.show();\n",
        "\n",
        "\n",
        "show_learning = ShowLearning()\n",
        "\n",
        "\n",
        "callbacks = [show_learning]\n",
        "\n",
        "# Model Compilation\n",
        "face_ae.compile(loss = 'mse', optimizer = \"adam\")"
      ],
      "metadata": {
        "id": "f18ULeSjc0XB",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:24:45.734325Z",
          "iopub.execute_input": "2021-05-30T14:24:45.734669Z",
          "iopub.status.idle": "2021-05-30T14:24:45.757013Z",
          "shell.execute_reply.started": "2021-05-30T14:24:45.73462Z",
          "shell.execute_reply": "2021-05-30T14:24:45.756211Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_training_history = face_ae.fit(train_imgs, train_imgs,\n",
        "                            epochs = EPOCHS,\n",
        "                            verbose = 1,\n",
        "                            validation_data = (val_imgs, val_imgs),\n",
        "                            batch_size = BS,\n",
        "                            shuffle = True,\n",
        "                            callbacks = callbacks)"
      ],
      "metadata": {
        "id": "G6SSeHCNdH0C",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:24:47.752766Z",
          "iopub.execute_input": "2021-05-30T14:24:47.75311Z",
          "iopub.status.idle": "2021-05-30T14:25:49.941258Z",
          "shell.execute_reply.started": "2021-05-30T14:24:47.753081Z",
          "shell.execute_reply": "2021-05-30T14:25:49.940407Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Results**"
      ],
      "metadata": {
        "id": "HwVex_Z57nfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing our training and validation losses\n",
        "train_loss = face_training_history.history[\"loss\"]\n",
        "val_loss = face_training_history.history[\"val_loss\"]\n",
        "epochs = [d for d in range(1,EPOCHS + 1)]\n",
        "\n",
        "# Code for plotting train and val loss\n",
        "plt.figure(figsize=(18, 10))\n",
        "plt.plot(epochs, train_loss, '-r', label=\"Training\")\n",
        "plt.plot(epochs, val_loss, '--b', label=\"Validation\")\n",
        "plt.title(\"LOSS Curve for Face reconstruction\")\n",
        "plt.grid(True)\n",
        "plt.xlabel('Epochs'); plt.ylabel(\"LOSS\")\n",
        "plt.legend()\n",
        "plt.xticks(epochs)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "o52Cc_yy7sE8",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:26:46.438555Z",
          "iopub.execute_input": "2021-05-30T14:26:46.438911Z",
          "iopub.status.idle": "2021-05-30T14:26:46.674318Z",
          "shell.execute_reply.started": "2021-05-30T14:26:46.43888Z",
          "shell.execute_reply": "2021-05-30T14:26:46.673458Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = face_ae.predict(val_imgs)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "  # display original\n",
        "  idx = np.random.randint(i, len(val_imgs))\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(val_imgs[idx])\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display reconstruction\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(decoded_imgs[idx])\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l5Dw2D28kCTd",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:26:57.553569Z",
          "iopub.execute_input": "2021-05-30T14:26:57.553905Z",
          "iopub.status.idle": "2021-05-30T14:26:58.979106Z",
          "shell.execute_reply.started": "2021-05-30T14:26:57.553875Z",
          "shell.execute_reply": "2021-05-30T14:26:58.978254Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Objective#3 : Image Denoising via Autoencoder**"
      ],
      "metadata": {
        "id": "MjNR7Zzh7Azp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\"><img src=\"https://miro.medium.com/max/724/1*qKiQ1noZdw8k05-YRIl6hw.jpeg\" width=\"800px\" height=\"400px\"/></div>"
      ],
      "metadata": {
        "id": "7uG_jmVuBdAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_factor = 0.3\n",
        "train_noisy_imgs = train_imgs + noise_factor*tf.random.normal(shape=train_imgs.shape)\n",
        "val_noisy_imgs = val_imgs + noise_factor*tf.random.normal(shape=val_imgs.shape)\n",
        "\n",
        "train_noisy_imgs = tf.clip_by_value(train_noisy_imgs, clip_value_min = 0., clip_value_max = 1.)\n",
        "val_noisy_imgs = tf.clip_by_value(val_noisy_imgs, clip_value_min = 0., clip_value_max = 1.)"
      ],
      "metadata": {
        "id": "CQ9Xe2EzsxJo",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:27:24.13348Z",
          "iopub.execute_input": "2021-05-30T14:27:24.133818Z",
          "iopub.status.idle": "2021-05-30T14:27:24.738138Z",
          "shell.execute_reply.started": "2021-05-30T14:27:24.133787Z",
          "shell.execute_reply": "2021-05-30T14:27:24.737215Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 7\n",
        "plt.figure(figsize=(20, 6))\n",
        "for i in range(1, n + 1):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    idx = np.random.randint(len(train_imgs))\n",
        "    plt.imshow(train_imgs[idx]);\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    plt.title(\"Original\")\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(train_noisy_imgs[idx]);\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    plt.title(\"Original + Noise\")\n",
        "\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "SP4-LGrk9cfz",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:27:28.072983Z",
          "iopub.execute_input": "2021-05-30T14:27:28.073308Z",
          "iopub.status.idle": "2021-05-30T14:27:29.088411Z",
          "shell.execute_reply.started": "2021-05-30T14:27:28.073277Z",
          "shell.execute_reply": "2021-05-30T14:27:29.087495Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (128, 128, 3)\n",
        "fae = Face_Autoencoder(input_dim = IMG_SHAPE,\n",
        "                    encoder_conv_filters=[32,64,64,64],\n",
        "                    encoder_conv_kernel_size=[3,3,3,3],\n",
        "                    encoder_conv_strides=[2,2,2,2],\n",
        "                    decoder_conv_t_filters=[64,64,32,3],\n",
        "                    decoder_conv_t_kernel_size=[3,3,3,3],\n",
        "                    decoder_conv_t_strides=[2,2,2,2],\n",
        "                    z_dim=128,\n",
        "                    use_batch_norm = False,\n",
        "                    use_dropout = False)\n",
        "\n",
        "denoisy_fae = fae.build()"
      ],
      "metadata": {
        "id": "PEKFZNy8-K7a",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:27:29.332958Z",
          "iopub.execute_input": "2021-05-30T14:27:29.333279Z",
          "iopub.status.idle": "2021-05-30T14:27:29.450334Z",
          "shell.execute_reply.started": "2021-05-30T14:27:29.33325Z",
          "shell.execute_reply": "2021-05-30T14:27:29.449661Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Hyperparamters\n",
        "LR = 1e-3\n",
        "BS = 16\n",
        "EPOCHS = 10\n",
        "\n",
        "# Model Compilation\n",
        "denoisy_fae.compile(loss = 'mse', optimizer = \"adam\")"
      ],
      "metadata": {
        "id": "-STELdDz_3EF",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:27:34.782693Z",
          "iopub.execute_input": "2021-05-30T14:27:34.783009Z",
          "iopub.status.idle": "2021-05-30T14:27:34.797234Z",
          "shell.execute_reply.started": "2021-05-30T14:27:34.78298Z",
          "shell.execute_reply": "2021-05-30T14:27:34.796472Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "denoisy_training_history = denoisy_fae.fit(train_noisy_imgs, train_imgs,\n",
        "                            epochs = EPOCHS,\n",
        "                            batch_size = BS,\n",
        "                            shuffle = True,\n",
        "                            validation_data = (val_noisy_imgs, val_imgs))"
      ],
      "metadata": {
        "id": "trgZ6xttAVwJ",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:27:38.872584Z",
          "iopub.execute_input": "2021-05-30T14:27:38.872921Z",
          "iopub.status.idle": "2021-05-30T14:27:57.750365Z",
          "shell.execute_reply.started": "2021-05-30T14:27:38.872884Z",
          "shell.execute_reply": "2021-05-30T14:27:57.74966Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Results**"
      ],
      "metadata": {
        "id": "V6gNHEAq9Pl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing our training and validation losses\n",
        "train_loss = denoisy_training_history.history[\"loss\"]\n",
        "val_loss = denoisy_training_history.history[\"val_loss\"]\n",
        "epochs = [d for d in range(1,EPOCHS + 1)]\n",
        "\n",
        "# Code for plotting train and val loss\n",
        "plt.figure(figsize=(18, 10))\n",
        "plt.plot(epochs, train_loss, '-r', label=\"Training\")\n",
        "plt.plot(epochs, val_loss, '--b', label=\"Validation\")\n",
        "plt.title(\"LOSS Curve for Face reconstruction\")\n",
        "plt.grid(True)\n",
        "plt.xlabel('Epochs'); plt.ylabel(\"LOSS\")\n",
        "plt.legend()\n",
        "plt.xticks(epochs)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "j1V73Zcg9TUF",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:30:22.233588Z",
          "iopub.execute_input": "2021-05-30T14:30:22.233964Z",
          "iopub.status.idle": "2021-05-30T14:30:22.432078Z",
          "shell.execute_reply.started": "2021-05-30T14:30:22.233933Z",
          "shell.execute_reply": "2021-05-30T14:30:22.431351Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = denoisy_fae.predict(val_noisy_imgs)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "\n",
        "    # display original + noise\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.title(\"original + noise\")\n",
        "    idx = np.random.randint(i, len(val_imgs))\n",
        "    plt.imshow(tf.squeeze(val_noisy_imgs[idx]))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    bx = plt.subplot(2, n, i + n + 1)\n",
        "    plt.title(\"reconstructed\")\n",
        "    plt.imshow(tf.squeeze(decoded_imgs[idx]))\n",
        "    plt.gray()\n",
        "    bx.get_xaxis().set_visible(False)\n",
        "    bx.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uBcSzV7AA22E",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:30:27.993442Z",
          "iopub.execute_input": "2021-05-30T14:30:27.993765Z",
          "iopub.status.idle": "2021-05-30T14:30:29.322063Z",
          "shell.execute_reply.started": "2021-05-30T14:30:27.993734Z",
          "shell.execute_reply": "2021-05-30T14:30:29.321254Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Objective#4 : Face identification via Autoencoder**"
      ],
      "metadata": {
        "id": "Dm_5C4OwRswJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4><b>What is Face Recognition</b></h4>\n",
        "<p>A facial recognition system is a technology capable of matching a human face from a digital image or a video frame against a database of faces, typically employed to authenticate users through ID verification services, works by pinpointing and measuring facial features from a given image.</p>"
      ],
      "metadata": {
        "id": "Mcj21qhOjXjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://www.learnopencv.com/wp-content/uploads/2019/04/face_verification_vs_recognition.jpg\"/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "pvaZWI-8SNvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4><em><strong>Face Verification is</strong> 1 : 1 MATCHING</em></h4>\n",
        "<h5><em>where as</em></h5>\n",
        "    <h4><em><strong>Face Identification is</strong> 1 : N MATCHING</em></h4>"
      ],
      "metadata": {
        "id": "O22ykq5KopL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building our Encoder"
      ],
      "metadata": {
        "id": "9QVG6PPEk6Hg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>We are iterating over the layers, so as to get the index of our embedding layer</p>\n"
      ],
      "metadata": {
        "id": "oJoKAlkBlBYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(face_ae.layers):\n",
        "    print(i, layer.name)"
      ],
      "metadata": {
        "id": "i3dGUIVRBSmk",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:30:45.234186Z",
          "iopub.execute_input": "2021-05-30T14:30:45.23451Z",
          "iopub.status.idle": "2021-05-30T14:30:45.245984Z",
          "shell.execute_reply.started": "2021-05-30T14:30:45.234481Z",
          "shell.execute_reply": "2021-05-30T14:30:45.244965Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>We are using <strong>Model</Strong> class from tf.keras.model submodule to build our Encoder. It requires the input layer and the output layer. We can also pass a name to our model by using the <em><b>name</b></em> parameter.</p>"
      ],
      "metadata": {
        "id": "jDMzxCY7loaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(face_ae.input, face_ae.layers[10].output, name=\"Encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "JUjgxykLScXW",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:30:47.013076Z",
          "iopub.execute_input": "2021-05-30T14:30:47.013388Z",
          "iopub.status.idle": "2021-05-30T14:30:47.027744Z",
          "shell.execute_reply.started": "2021-05-30T14:30:47.013359Z",
          "shell.execute_reply": "2021-05-30T14:30:47.026236Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Here, I am considering 3 classes from my training set</p>"
      ],
      "metadata": {
        "id": "PME7RJE8mR9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub1_encs = []\n",
        "sub2_encs = []\n",
        "sub3_encs = []\n",
        "\n",
        "def preprocess_img(image):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = image.astype('float32')\n",
        "    image = image/255.\n",
        "    image = cv2.resize(image, (128, 128))\n",
        "    return image\n",
        "\n",
        "\n",
        "for sub_img in os.listdir(\"../input/only-faces/Only_faces/Training/Subject1\")[:10]:\n",
        "    image = cv2.imread(os.path.join(\"../input/only-faces/Only_faces/Training/Subject1\", sub_img))\n",
        "    image = preprocess_img(image)\n",
        "    enc_img = encoder.predict(np.array([image]))\n",
        "    sub1_encs.append(enc_img)\n",
        "\n",
        "for sub_img in os.listdir(\"../input/only-faces/Only_faces/Training/Subject2\")[:10]:\n",
        "    image = cv2.imread(os.path.join(\"../input/only-faces/Only_faces/Training/Subject2\", sub_img))\n",
        "    image = preprocess_img(image)\n",
        "    enc_img = encoder.predict(np.array([image]))\n",
        "    sub2_encs.append(enc_img)\n",
        "\n",
        "for sub_img in os.listdir(\"../input/only-faces/Only_faces/Training/Subject3\")[:10]:\n",
        "    image = cv2.imread(os.path.join(\"../input/only-faces/Only_faces/Training/Subject3\", sub_img))\n",
        "    image = preprocess_img(image)\n",
        "    enc_img = encoder.predict(np.array([image]))\n",
        "    sub3_encs.append(enc_img)\n",
        "\n",
        "sub1_encs = np.array(sub1_encs)\n",
        "sub2_encs = np.array(sub2_encs)\n",
        "sub3_encs = np.array(sub3_encs)"
      ],
      "metadata": {
        "id": "yBaMo8lvSrVP",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:35:31.174107Z",
          "iopub.execute_input": "2021-05-30T14:35:31.174591Z",
          "iopub.status.idle": "2021-05-30T14:35:32.146362Z",
          "shell.execute_reply.started": "2021-05-30T14:35:31.174552Z",
          "shell.execute_reply": "2021-05-30T14:35:32.145529Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating base encodings for our subjects\n",
        "\n",
        "sub1_enc = np.mean(sub1_encs, axis = 0)\n",
        "sub2_enc = np.mean(sub2_encs, axis = 0)\n",
        "sub3_enc = np.mean(sub3_encs, axis = 0)"
      ],
      "metadata": {
        "id": "GNy3RUVlVrZ4",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:35:39.403214Z",
          "iopub.execute_input": "2021-05-30T14:35:39.403527Z",
          "iopub.status.idle": "2021-05-30T14:35:39.409827Z",
          "shell.execute_reply.started": "2021-05-30T14:35:39.403498Z",
          "shell.execute_reply": "2021-05-30T14:35:39.408859Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_idx = np.random.randint(len(val_imgs))\n",
        "\n",
        "\n",
        "rand_sub1_img = cv2.imread(os.path.join(\"../input/only-faces/Only_faces/Validation/Subject1\",\n",
        "                                        os.listdir(\"../input/only-faces/Only_faces/Validation/Subject1\")[np.random.randint(len(os.listdir(\"../input/only-faces/Only_faces/Validation/Subject1\")))]))\n",
        "\n",
        "rand_sub2_img = cv2.imread(os.path.join(\"../input/only-faces/Only_faces/Validation/Subject2\",\n",
        "                                        os.listdir(\"../input/only-faces/Only_faces/Validation/Subject2\")[np.random.randint(len(os.listdir(\"../input/only-faces/Only_faces/Validation/Subject2\")))]))\n",
        "\n",
        "rand_sub3_img = cv2.imread(os.path.join(\"../input/only-faces/Only_faces/Validation/Subject3\",\n",
        "                                        os.listdir(\"../input/only-faces/Only_faces/Validation/Subject3\")[np.random.randint(len(os.listdir(\"../input/only-faces/Only_faces/Validation/Subject3\")))]))\n",
        "\n",
        "rand_sub1_img = preprocess_img(rand_sub1_img)\n",
        "rand_sub2_img = preprocess_img(rand_sub2_img)\n",
        "rand_sub3_img = preprocess_img(rand_sub3_img)\n",
        "\n",
        "rand_sub1_enc = np.mean(encoder.predict(np.array([rand_sub1_img])), axis = 0)\n",
        "rand_sub2_enc = np.mean(encoder.predict(np.array([rand_sub2_img])), axis = 0)\n",
        "rand_sub3_enc = np.mean(encoder.predict(np.array([rand_sub3_img])), axis = 0)"
      ],
      "metadata": {
        "id": "HzrMlbQcY6DZ",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:33:35.573923Z",
          "iopub.execute_input": "2021-05-30T14:33:35.574251Z",
          "iopub.status.idle": "2021-05-30T14:33:35.687386Z",
          "shell.execute_reply.started": "2021-05-30T14:33:35.574222Z",
          "shell.execute_reply": "2021-05-30T14:33:35.686662Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will scipy's euclidean distance function to calculate the closeness between two images"
      ],
      "metadata": {
        "id": "lkeZEyxMiCYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def euclidean_dist(base_encs, unknown_enc):\n",
        "    distances = []\n",
        "    for base_enc in base_encs:\n",
        "        distances.append(euclidean(base_enc, unknown_enc))\n",
        "    distances  = np.array(distances)\n",
        "    return distances"
      ],
      "metadata": {
        "id": "uTB8cdl5bang",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:34:00.873912Z",
          "iopub.execute_input": "2021-05-30T14:34:00.874233Z",
          "iopub.status.idle": "2021-05-30T14:34:00.879173Z",
          "shell.execute_reply.started": "2021-05-30T14:34:00.874204Z",
          "shell.execute_reply": "2021-05-30T14:34:00.878175Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "base-encs : DB containing image encodings of subjects\n",
        "rand_encs : Random subjects\n",
        "rand_encs : Encodings of random subjects\n",
        "\n",
        "\"\"\"\n",
        "base_encs = [sub1_enc, sub2_enc, sub3_enc]\n",
        "rand_imgs = [rand_sub1_img, rand_sub2_img, rand_sub3_img]\n",
        "rand_encs = [rand_sub1_enc, rand_sub2_enc, rand_sub3_enc]\n",
        "\n",
        "distances = []\n",
        "for rand_enc in rand_encs:\n",
        "    distances.append(euclidean_dist(base_encs, rand_enc))\n",
        "subjects = [\"SUBJECT1\", \"SUBJECT2\", \"SUBJECT3\"]\n",
        "distances"
      ],
      "metadata": {
        "id": "_fV-gsWCcMnd",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:35:48.578407Z",
          "iopub.execute_input": "2021-05-30T14:35:48.578742Z",
          "iopub.status.idle": "2021-05-30T14:35:48.588598Z",
          "shell.execute_reply.started": "2021-05-30T14:35:48.578713Z",
          "shell.execute_reply": "2021-05-30T14:35:48.587714Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# analogue to DataBase contaning employess images\n",
        "\n",
        "base_imgs = [train_imgs[train_labels.index('Subject1')],\n",
        "            train_imgs[train_labels.index('Subject2')],\n",
        "            train_imgs[train_labels.index('Subject3')]]"
      ],
      "metadata": {
        "id": "j3QdVjBNgMpm",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:39:49.313813Z",
          "iopub.execute_input": "2021-05-30T14:39:49.314136Z",
          "iopub.status.idle": "2021-05-30T14:39:49.319347Z",
          "shell.execute_reply.started": "2021-05-30T14:39:49.314108Z",
          "shell.execute_reply": "2021-05-30T14:39:49.318179Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets check for our 1st random image"
      ],
      "metadata": {
        "id": "ltO1B8eziCYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 17))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.title('UNKOWN')\n",
        "plt.imshow(rand_imgs[0])\n",
        "plt.xlabel(f\"Identified as : {subjects[np.argmin(distances[0])]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.title('SUBJECT1')\n",
        "plt.imshow(base_imgs[0])\n",
        "plt.xlabel(f\"Distance : {distances[0][0]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.title('SUBJECT2')\n",
        "plt.imshow(base_imgs[1])\n",
        "plt.xlabel(f\"Distance : {distances[0][1]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.title('SUBJECT3')\n",
        "plt.imshow(base_imgs[2])\n",
        "plt.xlabel(f\"Distance : {distances[0][2]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "\n",
        "\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "2kfZS3kweX3L",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:39:58.298764Z",
          "iopub.execute_input": "2021-05-30T14:39:58.299077Z",
          "iopub.status.idle": "2021-05-30T14:39:58.656526Z",
          "shell.execute_reply.started": "2021-05-30T14:39:58.299049Z",
          "shell.execute_reply": "2021-05-30T14:39:58.655514Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets check for our 2nd random image"
      ],
      "metadata": {
        "id": "eM2_6wjGiCYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 17))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.title('UNKOWN')\n",
        "plt.imshow(rand_imgs[1])\n",
        "plt.xlabel(f\"Identified as : {subjects[np.argmin(distances[1])]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.title('SUBJECT1')\n",
        "plt.imshow(base_imgs[0])\n",
        "plt.xlabel(f\"Distance : {distances[1][0]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.title('SUBJECT2')\n",
        "plt.imshow(base_imgs[1])\n",
        "plt.xlabel(f\"Distance : {distances[1][1]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.title('SUBJECT3')\n",
        "plt.imshow(base_imgs[2])\n",
        "plt.xlabel(f\"Distance : {distances[1][2]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "\n",
        "\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "75zOtKTHfgoU",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:40:04.433147Z",
          "iopub.execute_input": "2021-05-30T14:40:04.433457Z",
          "iopub.status.idle": "2021-05-30T14:40:05.049995Z",
          "shell.execute_reply.started": "2021-05-30T14:40:04.433422Z",
          "shell.execute_reply": "2021-05-30T14:40:05.049124Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets check for our 3rd random image"
      ],
      "metadata": {
        "id": "QwRn_hLiiCYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 17))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.title('UNKOWN')\n",
        "plt.imshow(rand_imgs[2])\n",
        "plt.xlabel(f\"Identified as : {subjects[np.argmin(distances[2])]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.title('SUBJECT1')\n",
        "plt.imshow(base_imgs[0])\n",
        "plt.xlabel(f\"Distance : {distances[2][0]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.title('SUBJECT2')\n",
        "plt.imshow(base_imgs[1])\n",
        "plt.xlabel(f\"Distance : {distances[2][1]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.title('SUBJECT3')\n",
        "plt.imshow(base_imgs[2])\n",
        "plt.xlabel(f\"Distance : {distances[2][2]}\")\n",
        "plt.xticks([]); plt.yticks([])\n",
        "\n",
        "\n",
        "\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "cSywJZIBh-NY",
        "execution": {
          "iopub.status.busy": "2021-05-30T14:40:11.483011Z",
          "iopub.execute_input": "2021-05-30T14:40:11.483323Z",
          "iopub.status.idle": "2021-05-30T14:40:11.85284Z",
          "shell.execute_reply.started": "2021-05-30T14:40:11.483294Z",
          "shell.execute_reply": "2021-05-30T14:40:11.851896Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we saw that the randomly choosen images were correctly identified"
      ],
      "metadata": {
        "id": "sNBC2lJ2iTlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Points to Remember !!!\n",
        "<img src=\"https://cdn1.vectorstock.com/i/thumb-large/95/50/pointing-to-forehead-emoticon-vector-27559550.jpg\"/>\n",
        "\n",
        "\n",
        "<ul>\n",
        "<li>Data specific compression</li>\n",
        "<li>Unsupervised</li>\n",
        "<li>Lossy in nature</li>\n",
        "</ul>\n"
      ],
      "metadata": {
        "id": "A6NkEmewidzW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wA2OshJhiCYQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}